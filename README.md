# GovAssist AI ğŸ’¼ğŸ¤–

GovAssist AI is an end-to-end AI-powered automation system built for government social support departments. It processes applications in minutes using locally hosted multimodal agents, large language models (LLMs), and agentic orchestration. Designed for scalability, explainability, and fairness.

---

## ğŸš€ Features

- âœ… Fully automated decision-making pipeline (extract â†’ validate â†’ decide)
- ğŸ“„ Multimodal document ingestion (PDFs, images, Excel)
- ğŸ§  ML-based eligibility classification (Random Forest)
- ğŸ’¬ Chatbot assistant powered by local LLM (Ollama)
- ğŸ“ Appeal and feedback submission system
- ğŸ“Š Admin dashboard for audit and analytics
- ğŸ”— LangGraph-based agent orchestration
- ğŸ§¾ PostgreSQL for decisions + appeals tracking

---

## ğŸ“‚ Folder Structure

```
govassist_ai/
â”œâ”€â”€ agents/             # Core agents: extraction, validation, eligibility, enablement
â”œâ”€â”€ chat/               # LLM-powered chatbot assistant
â”œâ”€â”€ frontend/           # Gradio user interface and appeal/dashboard modules
â”œâ”€â”€ models/             # Training script and ML model
â”œâ”€â”€ orchestration/      # LangGraph-based pipeline orchestrator
â”œâ”€â”€ samples/            # Sample documents for testing
â”œâ”€â”€ storage/            # PostgreSQL table schema
â”œâ”€â”€ main_test_pipeline.py   # CLI pipeline runner (no UI)
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ config.yaml         # App config template
â””â”€â”€ README.md           # This file
```

---

## ğŸ“¦ Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/govassist_ai.git
cd govassist_ai
```

### 2. Create a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Setup PostgreSQL

```sql
-- Run this in your PostgreSQL shell
CREATE DATABASE govassist;

-- Then execute:
psql -d govassist -f storage/postgres_config.sql
```

### 5. Pull a local LLM using Ollama

```bash
# Install Ollama: https://ollama.com/download
ollama pull mistral
```

---

## ğŸ§ª Run the Full System

```bash
python frontend/frontend_app.py
```

Visit `http://localhost:7860` to use:
- ğŸ“¤ Application Upload
- ğŸ’¬ Chatbot Assistant
- ğŸ“ Appeal Submission
- ğŸ“Š Admin Dashboard

---

## ğŸ§  Orchestration Engine

We use **LangGraph** to orchestrate agents:
- `DataExtractionAgent`
- `ValidationAgent`
- `EligibilityAgent`
- `EnablementAgent`

You can run the orchestrator standalone with:

```bash
python orchestration/orchestrator.py
```

---

## ğŸ“Š Admin Dashboard

- Visual insights from applications
- Filter decisions, top job matches
- View appeal text + re-evaluation requests

---

## ğŸ” LLM Hosting Locally

We use [Ollama](https://ollama.com/) to run models like Mistral or LLaMA3 locally:
- Private
- Fast inference
- No internet needed

---

## ğŸ› ï¸ Tools & Stack

| Layer              | Tools Used                                    |
|--------------------|-----------------------------------------------|
| UI                 | Gradio                                        |
| Agent Orchestration| LangGraph, LangChain                          |
| ML Models          | scikit-learn (RandomForest)                  |
| Embeddings + Search| SentenceTransformers + ChromaDB              |
| LLM                | Mistral via Ollama                            |
| Storage            | PostgreSQL                                    |

---

## ğŸ“Œ Author & Credits

Developed by: **Your Name**  
For demo purposes in government enablement + AI automation systems.

---

## ğŸ“ƒ License

MIT License. Use responsibly.